{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 6:  Train Various Regression Models and Compare Their Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab assignment, you will train various regression models (regressors) and compare their performances. You will train, test and evaluate individual models as well as ensemble models. You will:\n",
    "\n",
    "1. Build your DataFrame and define your ML problem:\n",
    "    * Load the Airbnb \"listings\" data set\n",
    "    * Define the label - what are you predicting?\n",
    "    * Identify the features\n",
    "2. Create labeled examples from the data set.\n",
    "3. Split the data into training and test data sets.\n",
    "4. Train, test and evaluate two individual regressors.\n",
    "5. Use the stacking ensemble method to train the same regressors.\n",
    "6. Train, test and evaluate Gradient Boosted Decision Trees.\n",
    "7. Train, test and evaluate Random Forest.\n",
    "8. Visualize and compare the performance of all of the models.\n",
    "\n",
    "<font color='red'><b>Note:</font><br> \n",
    "<font color='red'><b>1. Some of the code cells in this notebook may take a while to run.</font><br>\n",
    "<font color='red'><b>2. Ignore warning messages that pertain to deprecated packages.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Build Your DataFrame and Define Your ML Problem\n",
    "\n",
    "#### Load a Data Set and Save it as a Pandas DataFrame\n",
    "\n",
    "We will work with the data set ``airbnbData_train``. This data set already has all the necessary preprocessing steps implemented, including one-hot encoding of the categorical variables, scaling of all numerical variable values, and imputing missing values. It is ready for modeling.\n",
    "\n",
    "<b>Task</b>: In the code cell below, use the same method you have been using to load the data using `pd.read_csv()` and save it to DataFrame `df`.\n",
    "\n",
    "You will be working with the file named \"airbnbData_train.csv\" that is located in a folder named \"data_regressors\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "filename = os.path.join(os.getcwd(), \"data_regressors\", \"airbnbData_train.csv\")\n",
    "\n",
    "df = pd.read_csv(filename, header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the Label\n",
    "\n",
    "Your goal is to train a machine learning model that predicts the price of an Airbnb listing. This is an example of supervised learning and is a regression problem. In our dataset, our label will be the `price` column and the label contains continuous values.\n",
    "\n",
    "#### Evaluation Metrics for Regressors\n",
    "\n",
    "So far, we have mostly focused on classification problems. For this assignment, we will focus on a regression problem and predict a continuous outcome. There are different evaluation metrics that are used to determine the performance of a regressor. We will use two metrics to evaluate our regressors: RMSE (root mean square error) and $R^2$ (coefficient of determination).\n",
    "\n",
    "RMSE:<br>\n",
    "RMSE finds the average difference between the predicted values and the actual values. We will compute the RMSE on the test set.  To compute the RMSE, we will use the scikit-learn ```mean_squared_error()``` function. Since RMSE finds the difference between the predicted and actual values, lower RMSE values indicate good performance - the model fits the data well and makes more accurate predictions. On the other hand, higher RSME values indicate that the model is not performing well.\n",
    "\n",
    "$R^2$:<br>\n",
    "$R^2$ is a measure of the proportion of variability in the prediction that the model was able to make using the test data. An $R^2$ value of 1 is perfect and 0 implies no explanatory value. We can use scikit-learn's ```r2_score()``` function to compute it. Since $R^2$ measures how well the model fits the data, a higher $R^2$ value indicates that good performance and a lower $R^2$ indicates that poor performance.\n",
    "\n",
    "#### Identify Features\n",
    "\n",
    "Our features will be all of the remaining columns in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Create Labeled Examples from the Data Set \n",
    "\n",
    "<b>Task</b>: In the code cell below, create labeled examples from DataFrame `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['host_is_superhost', 'host_has_profile_pic', 'host_identity_verified',\n",
       "       'has_availability', 'instant_bookable', 'host_response_rate',\n",
       "       'host_acceptance_rate', 'host_listings_count',\n",
       "       'host_total_listings_count', 'accommodates', 'bathrooms', 'bedrooms',\n",
       "       'beds', 'minimum_nights', 'maximum_nights', 'minimum_minimum_nights',\n",
       "       'maximum_minimum_nights', 'minimum_maximum_nights',\n",
       "       'maximum_maximum_nights', 'minimum_nights_avg_ntm',\n",
       "       'maximum_nights_avg_ntm', 'availability_30', 'availability_60',\n",
       "       'availability_90', 'availability_365', 'number_of_reviews',\n",
       "       'number_of_reviews_ltm', 'number_of_reviews_l30d',\n",
       "       'review_scores_rating', 'review_scores_cleanliness',\n",
       "       'review_scores_checkin', 'review_scores_communication',\n",
       "       'review_scores_location', 'review_scores_value',\n",
       "       'calculated_host_listings_count',\n",
       "       'calculated_host_listings_count_entire_homes',\n",
       "       'calculated_host_listings_count_private_rooms',\n",
       "       'calculated_host_listings_count_shared_rooms', 'reviews_per_month',\n",
       "       'n_host_verifications', 'neighbourhood_group_cleansed_Bronx',\n",
       "       'neighbourhood_group_cleansed_Brooklyn',\n",
       "       'neighbourhood_group_cleansed_Manhattan',\n",
       "       'neighbourhood_group_cleansed_Queens',\n",
       "       'neighbourhood_group_cleansed_Staten Island',\n",
       "       'room_type_Entire home/apt', 'room_type_Hotel room',\n",
       "       'room_type_Private room', 'room_type_Shared room'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "y = df['price']\n",
    "X = df.drop('price', axis=1,inplace=False)\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. Create Training and Test Data Sets\n",
    "\n",
    "<b>Task</b>: In the code cell below, create training and test sets out of the labeled examples. Create a test set that is 30 percent of the size of the data set. Save the results to variables `X_train, X_test, y_train, y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Train, Test and Evaluate Two Regression Models: Linear Regression and Decision Tree\n",
    "\n",
    "### a. Train, Test and Evaluate a Linear Regression\n",
    "\n",
    "You will use the scikit-learn `LinearRegression` class to create a linear regression model. For more information, consult the online [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html).\n",
    "\n",
    "First let's import `LinearRegression`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task</b>: Initialize a scikit-learn `LinearRegression` model object with no arguments, and fit the model to the training data. The model object should be named `lr_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "lr_model = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task:</b> Test your model on the test set (`X_test`). Call the ``predict()`` method  to use the fitted model to generate a vector of predictions on the test set. Save the result to the variable ``y_lr_pred``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call predict() to use the fitted model to make predictions on the test data\n",
    "# YOUR CODE HERE\n",
    "y_lr_pred = lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the RMSE, we will use the scikit-learn ```mean_squared_error()``` function, which computes the mean squared error between the predicted values and the actual values: ```y_lr_pred``` and```y_test```. In order to obtain the root mean squared error, we will specify the parameter `squared=False`. \n",
    "\n",
    "To compute the $R^2$, we will use the scikit-learn ```r2_score()``` function. \n",
    "\n",
    "<b>Task</b>: In the code cell below, do the following:\n",
    "\n",
    "1. Call the `mean_squared_error()` function with arguments `y_test` and `y_lr_pred` and the parameter `squared=False` to find the RMSE. Save your result to the variable `lr_rmse`.\n",
    "\n",
    "2. Call the `r2_score()` function with the arguments `y_test` and `y_lr_pred`.  Save the result to the variable `lr_r2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LR] Root Mean Squared Error: 0.7332664574015512\n",
      "[LR] R2: 0.4605401584349824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 1. Compute the RMSE using mean_squared_error()\n",
    "# YOUR CODE HERE\n",
    "lr_rmse = mean_squared_error(y_test,y_lr_pred,squared=False)\n",
    "\n",
    "# 2. Compute the R2 score using r2_score()\n",
    "# YOUR CODE HERE\n",
    "lr_r2 = r2_score(y_test, y_lr_pred)\n",
    "\n",
    "print('[LR] Root Mean Squared Error: {0}'.format(lr_rmse))\n",
    "print('[LR] R2: {0}'.format(lr_r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Train, Test and Evaluate a Decision Tree Using GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will use the scikit-learn `DecisionTreeRegressor` class to create a decision tree regressor. For more information, consult the online [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html).\n",
    "\n",
    "First let's import `DecisionTreeRegressor`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Up a Parameter Grid \n",
    "\n",
    "<b>Task</b>: Create a dictionary called `param_grid` that contains possible hyperparameter values for `max_depth` and `min_samples_leaf`. The dictionary should contain the following key/value pairs:\n",
    "\n",
    "* a key called 'max_depth' with a value which is a list consisting of the integers 4 and 8\n",
    "* a key called 'min_samples_leaf' with a value which is a list consisting of the integers 25 and 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "param_grid = {'max_depth':[4,8], 'min_samples_leaf':[25,50]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task:</b> Use `GridSearchCV` to fit a grid of decision tree regressors and search over the different values of hyperparameters `max_depth` and `min_samples_leaf` to find the ones that results in the best 3-fold cross-validation (CV) score.\n",
    "\n",
    "\n",
    "You will pass the following arguments to `GridSearchCV()`:\n",
    "\n",
    "1. A decision tree **regressor** model object.\n",
    "2. The `param_grid` variable.\n",
    "3. The number of folds (`cv=3`).\n",
    "4. The scoring method `scoring='neg_root_mean_squared_error'`. Note that `neg_root_mean_squared_error` returns the negative RMSE.\n",
    "\n",
    "\n",
    "Complete the code in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Grid Search...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print('Running Grid Search...')\n",
    "\n",
    "# 1. Create a DecisionTreeRegressor model object without supplying arguments. \n",
    "#    Save the model object to the variable 'dt_regressor'\n",
    "\n",
    "dt_regressor = DecisionTreeRegressor()\n",
    "# 2. Run a Grid Search with 3-fold cross-validation and assign the output to the object 'dt_grid'.\n",
    "#    * Pass the model and the parameter grid to GridSearchCV()\n",
    "#    * Set the number of folds to 3\n",
    "#    * Specify the scoring method\n",
    "\n",
    "dt_grid = GridSearchCV(dt_regressor,param_grid,cv=3,scoring='neg_root_mean_squared_error')\n",
    "# 3. Fit the model (use the 'grid' variable) on the training data and assign the fitted model to the \n",
    "#    variable 'dt_grid_search'\n",
    "\n",
    "dt_grid_search = dt_grid.fit(X_train,y_train)\n",
    "\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code cell below prints the RMSE score of the best model using the `best_score_` attribute of the fitted grid search object `dt_grid_search`. Note that specifying a scoring method of `neg_root_mean_squared_error` will result in the negative RMSE, so we will multiply `dt_grid_search.best_score` by -1 to obtain the RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DT] RMSE for the best model is : 0.72\n"
     ]
    }
   ],
   "source": [
    "rmse_DT = -1 * dt_grid_search.best_score_\n",
    "print(\"[DT] RMSE for the best model is : {:.2f}\".format(rmse_DT) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task</b>: In the code cell below, obtain the best model hyperparameters identified by the grid search and save them to the variable `dt_best_params`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 8, 'min_samples_leaf': 25}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_best_params = dt_grid_search.best_params_\n",
    "\n",
    "dt_best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task</b>: In the code cell below, initialize a `DecisionTreeRegressor` model object, supplying the best values of hyperparameters `max_depth` and `min_samples_leaf` as arguments.  Name the model object `dt_model`. Then fit the model `dt_model` to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "dt_model = DecisionTreeRegressor(max_depth=dt_best_params['max_depth'],min_samples_leaf=dt_best_params['min_samples_leaf']).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task:</b> Test your model `dt_model` on the test set `X_test`. Call the ``predict()`` method  to use the fitted model to generate a vector of predictions on the test set. Save the result to the variable ``y_dt_pred``. Evaluate the results by computing the RMSE and R2 score in the same manner as you did above. Save the results to the variables `dt_rmse` and `dt_r2`.\n",
    "\n",
    "Complete the code in the cell below to accomplish this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DT] Root Mean Squared Error: 0.7122598588621462\n",
      "[DT] R2: 0.4910062835027976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 1. Use the fitted model to make predictions on the test data\n",
    "# YOUR CODE HERE\n",
    "y_dt_pred = dt_model.predict(X_test)\n",
    "\n",
    "# 2. Compute the RMSE using mean_squared_error()\n",
    "# YOUR CODE HERE\n",
    "dt_rmse = mean_squared_error(y_test,y_dt_pred,squared=False)\n",
    "\n",
    "# 3. Compute the R2 score using r2_score()\n",
    "# YOUR CODE HERE\n",
    "dt_r2 = r2_score(y_test,y_dt_pred)\n",
    "\n",
    "print('[DT] Root Mean Squared Error: {0}'.format(dt_rmse))\n",
    "print('[DT] R2: {0}'.format(dt_r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Train, Test and Evaluate Ensemble Models: Stacking "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will use the stacking ensemble method to train two regression models. You will use the scikit-learn `StackingRegressor` class. For more information, consult the online [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingRegressor.html).\n",
    "\n",
    "First let's import `StackingRegressor`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the assignment, we will use two models jointly. In the code cell below, we creates a list of tuples, each consisting of a scikit-learn model function and the corresponding shorthand name that we choose. We will specify the hyperparameters for the decision tree that we determined through the grid search above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [(\"DT\", DecisionTreeRegressor(max_depth=8, min_samples_leaf=25)),\n",
    "              (\"LR\", LinearRegression())\n",
    "             ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task</b>: \n",
    "\n",
    "\n",
    "1. Create a `StackingRegressor` model object. Call `StackingRegressor()` with the following parameters:\n",
    "    * Assign the list `estimators` to the parameter `estimators`.\n",
    "    * Use the parameter 'passthrough=False'. \n",
    "Assign the results to the variable `stacking_model`.\n",
    "\n",
    "2. Fit `stacking_model` to the training data.\n",
    "\n",
    "As you read up on the definition of the `StackingRegressor` class, you will notice that by default, the results of each model are combined using a ridge regression (a \"final regressor\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Implement Stacking...\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "print('Implement Stacking...')\n",
    "\n",
    "# YOUR CODE HERE\n",
    "stacking_model = StackingRegressor(estimators=estimators,passthrough=False).fit(X_train,y_train)\n",
    "\n",
    "print('End')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task:</b> Use the `predict()` method to test your ensemble model `stacking_model` on the test set (`X_test`). Save the result to the variable `stacking_pred`. Evaluate the results by computing the RMSE and R2 score. Save the results to the variables `stack_rmse` and `stack_r2`.\n",
    "\n",
    "Complete the code in the cell below to accomplish this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 0.6853455270782765\n",
      "R2: 0.528746435926555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 1. Use the fitted model to make predictions on the test data\n",
    "# YOUR CODE HERE\n",
    "stacking_pred = stacking_model.predict(X_test)\n",
    "\n",
    "# 2. Compute the RMSE \n",
    "# YOUR CODE HERE\n",
    "stack_rmse = mean_squared_error(y_test,stacking_pred,squared=False)\n",
    "\n",
    "# 3. Compute the R2 score\n",
    "# YOUR CODE HERE\n",
    "stack_r2 = r2_score(y_test,stacking_pred)\n",
    "   \n",
    "print('Root Mean Squared Error: {0}'.format(stack_rmse))\n",
    "print('R2: {0}'.format(stack_r2))                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Train, Test and Evaluate  Evaluate Ensemble Models: Gradient Boosted Decision Trees \n",
    "\n",
    "You will use the scikit-learn `GradientBoostingRegressor` class to create a gradient boosted decision tree. For more information, consult the online [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html).\n",
    "\n",
    "First let's import `GradientBoostingRegressor`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume you already performed a grid search to find the best model hyperparameters for your gradient boosted decision tree. (We are omitting this step to save computation time.) The best values are: `max_depth=2`, and `n_estimators = 300`. \n",
    "\n",
    "<b>Task</b>: Initialize a `GradientBoostingRegressor` model object with the above values as arguments. Save the result to the variable `gbdt_model`. Fit the `gbdt_model` model to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin GBDT Implementation...\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "print('Begin GBDT Implementation...')\n",
    "\n",
    "# YOUR CODE HERE\n",
    "gbdt_model = GradientBoostingRegressor(max_depth=2,n_estimators=300).fit(X_train,y_train)\n",
    "\n",
    "print('End')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task:</b> Use the `predict()` method to test your model `gbdt_model` on the test set `X_test`. Save the result to the variable ``y_gbdt_pred``. Evaluate the results by computing the RMSE and R2 score in the same manner as you did above. Save the results to the variables `gbdt_rmse` and `gbdt_r2`.\n",
    "\n",
    "Complete the code in the cell below to accomplish this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GBDT] Root Mean Squared Error: 0.6616425793300482\n",
      "[GBDT] R2: 0.5607797301389188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 1. Use the fitted model to make predictions on the test data\n",
    "# YOUR CODE HERE\n",
    "y_gbdt_pred = gbdt_model.predict(X_test)\n",
    "\n",
    "# 2. Compute the RMSE \n",
    "# YOUR CODE HERE\n",
    "gbdt_rmse = mean_squared_error(y_test,y_gbdt_pred,squared=False)\n",
    "\n",
    "# 3. Compute the R2 score \n",
    "# YOUR CODE HERE\n",
    "gbdt_r2 = r2_score(y_test,y_gbdt_pred)\n",
    "\n",
    "print('[GBDT] Root Mean Squared Error: {0}'.format(gbdt_rmse))\n",
    "print('[GBDT] R2: {0}'.format(gbdt_r2))                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Train, Test and Evaluate  Ensemble Models: Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will use the scikit-learn `RandomForestRegressor` class to create a gradient boosted decision tree. For more information, consult the online [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html).\n",
    "\n",
    "First let's import `RandomForestRegressor`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume you already performed a grid search to find the best model hyperparameters for your random forest model. (We are omitting this step to save computation time.) The best values are: `max_depth=32`, and `n_estimators = 300`. \n",
    "\n",
    "<b>Task</b>: Initialize a `RandomForestRegressor` model object with the above values as arguments. Save the result to the variable `rf_model`. Fit the `rf_model` model to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin RF Implementation...\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "print('Begin RF Implementation...')\n",
    "\n",
    "# YOUR CODE HERE\n",
    "rf_model = RandomForestRegressor(max_depth=32,n_estimators = 300).fit(X_train,y_train)\n",
    "\n",
    "print('End')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task:</b> Use the `predict()` method to test your model `rf_model` on the test set `X_test`. Save the result to the variable ``y_rf_pred``. Evaluate the results by computing the RMSE and R2 score in the same manner as you did above. Save the results to the variables `rf_rmse` and `rf_r2`.\n",
    "\n",
    "Complete the code in the cell below to accomplish this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RF] Root Mean Squared Error: 0.630437584359477\n",
      "[RF] R2: 0.6012325740244747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 1. Use the fitted model to make predictions on the test data\n",
    "# YOUR CODE HERE\n",
    "y_rf_pred = rf_model.predict(X_test)\n",
    "\n",
    "# 2. Compute the RMSE \n",
    "# YOUR CODE HERE\n",
    "rf_rmse = mean_squared_error(y_test,y_rf_pred,squared=False)\n",
    "\n",
    "# 3. Compute the R2 score \n",
    "# YOUR CODE HERE\n",
    "rf_r2 = r2_score(y_test,y_rf_pred)\n",
    "\n",
    "print('[RF] Root Mean Squared Error: {0}'.format(rf_rmse))\n",
    "print('[RF] R2: {0}'.format(rf_r2))                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Visualize and Compare Model Performance\n",
    "\n",
    "The code cell below will plot the RMSE and R2 score for each regressor. \n",
    "\n",
    "<b>Task:</b> Complete the code in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RMSE_Results = [stack_rmse, lr_rmse, dt_rmse, gbdt_rmse, rf_rmse]\n",
    "R2_Results = [stack_r2, lr_r2, dt_r2, gbdt_r2, rf_r2]\n",
    "\n",
    "rg= np.arange(5)\n",
    "width = 0.35\n",
    "\n",
    "# 1. Create bar plot with RMSE results\n",
    "# YOUR CODE HERE\n",
    "plt.bar(rg, RMSE_Results, width, label='RMSE')\n",
    "\n",
    "# 2. Create bar plot with R2 results\n",
    "# YOUR CODE HERE\n",
    "plt.bar(rg + width, R2_Results, width, label='R Score')\n",
    "\n",
    "\n",
    "labels = ['Stacking','LR', 'DT', 'GBDT', 'RF']\n",
    "plt.xticks(rg + width/2, labels)\n",
    "\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"RMSE/R2\")\n",
    "\n",
    "\n",
    "plt.ylim([0,1])\n",
    "plt.title('Model Performance')\n",
    "plt.legend(loc='upper left', ncol=2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Analysis</b>: Compare and contrast the resulting $R^2$ and RSME scores of the ensemble models and the individual models. Are the ensemble models performing better? Which is the best performing model? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the $R^2$ and RSME scores of all the ensemble and individual models this notebook has gone over, RMSE is always greater for this dataset than $R^2$, with RMSE around 0.65 or 0.7 generally, while $R^2$ is generally around 0.5. Between models, the ensemble models do tend to perform better with lower RMSE and higher $R^2$, with random forest performing the best, followed by GBDT and stacking, and then the non-ensemble models of decision trees and linear regression. This makes sense that the ensemble models perform better, as for moderately sized data, they generate a variety of models from varying amounts of the features, and take some sort of weighted sum, average or iterative reduction in error, as determined by the model type, to generate a final model in which model variations ideally cancel out and that go on to form the model closest to the truest model trend. Specifically, random forest ended up being the best model, as it was based on the averages of decision trees, of which there were a large number used, which improved the prediction without increasing overfitting, though in training the model, it did take much longer to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
